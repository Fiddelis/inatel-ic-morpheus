{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documenta\u00e7\u00e3o","text":"<p> Site criado para documentar os estudos referente a Inicia\u00e7\u00e3o Cientifica no CS&amp;I Lab sobre IA e Cyberseguran\u00e7a.</p> <p>Contatos</p> <p> Email: lucas.ruan@ges.inatel.br</p> <p> Linkedin: lucas-ruan-fidelis</p> <p> Github: Fiddelis@GitHub</p>"},{"location":"#assuntos-estudados","title":"Assuntos Estudados","text":"<ul> <li>SIEM</li> <li>Morpheus</li> <li>Triton Infer\u00eance Server</li> <li>Fontes</li> </ul>"},{"location":"Fontes/fontes/","title":"Fontes","text":""},{"location":"Fontes/fontes/#artigos","title":"Artigos","text":"<ul> <li>Security Information and Event Management (SIEM): Analysis, Trends, and Usage in Critical Infrastructures</li> <li>Effective Security Monitoring Using Efficient SIEM Architecture</li> <li>ARQUITETURA DE UM SIEM TOLERANTE A FALHAS PARA AN\u00c1LISE FORENSE</li> <li>Cybersecurity on a budget: Evaluating security and performance of open-source SIEM solutions for SMEs</li> <li>Integrating Security Information and Event Management (SIEM) with Data Lakes and AI: Enhancing Threat Detection and Response</li> <li>Enhancing Security Operations Center Efficiency Through Multi-Model Integration of Large Language Models and Siem System</li> </ul>"},{"location":"Morpheus/0.introdu%C3%A7%C3%A3o/","title":"0. Introdu\u00e7\u00e3o ao Morpheus","text":"<p>O Morpheus \u00e9 uma Framework de seguran\u00e7a cibern\u00e9tica da NVIDIA de c\u00f3digo aberto, acelerada por GPU, que permite a cria\u00e7\u00e3o de pipelines otimizados para filtrar, processar e classificar um grande volume de dados em tempo real permitindo uma detec\u00e7\u00e3o mais r\u00e1pida.</p>"},{"location":"Morpheus/0.introdu%C3%A7%C3%A3o/#principais-recursos","title":"Principais recursos","text":"<ul> <li>A acelera\u00e7\u00e3o da GPU no Morpheus oferece o mais alto desempenho, em grande escala, permitindo que as empresas inspecionem e analisem todos os dados e tr\u00e1fego em toda a rede, incluindo data center, edge, gateway e computa\u00e7\u00e3o centralizada.</li> <li>Aproveita infer\u00eancia e acelera\u00e7\u00e3o de GPU em escala (at\u00e9 600 vezes mais r\u00e1pida do que solu\u00e7\u00f5es somente de CPU) reduzindo o tempo de detec\u00e7\u00e3o de semanas para minutos.</li> </ul>"},{"location":"Morpheus/0.introdu%C3%A7%C3%A3o/#beneficios","title":"Benef\u00edcios","text":"<ul> <li>Permite que desenvolvedores criem suas pr\u00f3prias solu\u00e7\u00f5es de seguran\u00e7a cibern\u00e9tica.</li> <li>Permite a adapta\u00e7\u00e3o din\u00e2mica a feedback humano e eventos externos, melhorando a precis\u00e3o e a capacidade de resposta dos modelos de IA.</li> <li>Poss\u00edvel Implementar o pr\u00f3prio modelo ou alguns dos modelos pr\u00e9-treinados e testados pela pr\u00f3pria NVIDIA.</li> </ul>"},{"location":"Morpheus/1.container_morpheus/","title":"1. Configura\u00e7\u00e3o do Morpheus com Docker","text":"<p>A NVIDIA disponibiliza Imagens pr\u00e9-configuradas de containers que nos permite utilizar o Morpheus sem a necessidade de ter instalado na sua pr\u00f3pria maquina, permitindo a execu\u00e7\u00e3o de testes de forma r\u00e1pida e funcional.</p> <p>No momento que estou escrevendo esse documento, o Morpheus se encontra na vers\u00e3o 24.06(LTE).</p>"},{"location":"Morpheus/1.container_morpheus/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Arquitetura Volta de GPU ou melhor.</li> <li>CUDA 12.1</li> <li>Docker</li> <li>The NVIDIA Container Toolkit</li> </ul>"},{"location":"Morpheus/1.container_morpheus/#download-da-imagem","title":"Download da Imagem","text":"<p>Com o Docker ja instalado na sua maquina, precisamos baixar a imagem na nuvem da NVIDIA (NGC).</p> <pre><code>docker pull nvcr.io/nvidia/morpheus/morpheus:24.06-runtime\n</code></pre> <p>Para verificar se o comando funcionou corretamente, execute o comando abaixo para listar todas as imagens instaladas no Docker:</p> <pre><code>docker ps\n</code></pre> Failure <p>Caso a imagem n\u00e3o se encontre na lista, verifique se inseriu a tag corretamente e tente novamente.</p>"},{"location":"Morpheus/1.container_morpheus/#executando-o-morpheus","title":"Executando o Morpheus","text":"<p>Para Utilizar o Morpheus basta executar o seguinte comando no terminal:</p> <pre><code>docker run --rm -ti --runtime=nvidia --gpus=all --network=host nvcr.io/nvidia/morpheus/morpheus:24.06-runtime bash\n</code></pre> <p>Isso vai fazer com que um container seja criado e executado no seu terminal, ao finalizar a sess\u00e3o ser\u00e1 apagado o container junto com os arquivos que foram gerados.</p> <p>Dentro do Bash do container \u00e9 possivel executar qualquer tipo de comando relacionado ao Morpheus, tal qual:</p> <pre><code>morpheus run --help\n</code></pre>"},{"location":"Morpheus/2.arquitetura_morpheus/","title":"2. Arquitetura e Componentes do Morpheus","text":"<p>A arquitetura do Morpheus pode ser dividida em algumas camadas.</p>"},{"location":"Morpheus/2.arquitetura_morpheus/#camada-de-pipeline","title":"Camada de Pipeline","text":"<p>Essa camada \u00e9 responsavel por orquestrar os est\u00e1gios que s\u00e3o conectados por arestas. Os dados de movem atr\u00e1ves dos canais de buffers, e o pipeline cuida automaticamente da contrapress\u00e3o monitorando a quantidade de dados em cada buffer de borda.</p> <p>\u00c9 utilizado buffers para permitir que est\u00e1gios processem mensagens em taxas diferentes. Ao termino de um est\u00e1gio, \u00e9 passado para o pr\u00f3ximo buffer, fazendo isso at\u00e9 que tenha terminado o processamento do pipeline.</p> <p>O principal objetivo do pipeline \u00e9 maximizar o rendimento atrav\u00e9s da execu\u00e7\u00e3o paralela dos est\u00e1gios. Assim, podemos utilizar o hardware de forma otimizada e evitar processar mensagens individuais sequencialmente.</p> <p>Dado um pipeline que consiste nos Est\u00e1gios 1 e 2.</p> <ol> <li>O est\u00e1gio 1 coleta sua primeira mensagem de sua fonte de dados e come\u00e7a a process\u00e1-la.</li> <li>Uma vez que o est\u00e1gio 1 \u00e9 feito com a sua primeira mensagem, a mensagem de sa\u00edda resultante ser\u00e1 encaminhada para o Est\u00e1gio 2.</li> <li>Neste ponto, o Est\u00e1gio 1 come\u00e7a imediatamente o processamento da pr\u00f3xima entrada para o pipeline, enquanto o Est\u00e1gio 2 come\u00e7a a trabalhar na sa\u00edda do Est\u00e1gio 1.</li> </ol> <p>Utilizar buffers entre os est\u00e1gios tem um custo. Aumentar o tamanho do buffer ajuda a melhorar o paralelismo, garantindo que todas as etapas tenha algum trabalho a fazer. Mas isso tamb\u00e9m pode aumentar a lat\u00eancia, ja que as mensagens podem ficar em um buffer esperando para ser processada. O inverso tamb\u00e9m \u00e9 verdade, diminuir o tamanho do buffer melhora a lat\u00eancia, mas alguns est\u00e1gios podem ficar sem trabalho, diminuindo assim o paralelismo. \u00c9 preciso escolher com cuidado o tamanho dos buffers para aumentar ao m\u00e1ximo a efici\u00eancia.</p>"},{"location":"Morpheus/2.arquitetura_morpheus/#camada-de-estagio","title":"Camada de Est\u00e1gio","text":"<p>O est\u00e1gio \u00e9 a parte fundamental para o Morpheus, \u00e9 ele o responsavel por realizar todo o trabalho de processamento de um Pipeline.</p> <p>O est\u00e1gio pode encapsular qualquer funcionalidade e pode integrar qualquer servi\u00e7o ou biblioteca externa. Isso faz com que est\u00e1gios variem de fun\u00e7\u00f5es pequenas para at\u00e9 em uma infer\u00eancia muito complexa, que conecte-se a servi\u00e7os e trabalhe em v\u00e1rios threads.</p> <p>Exemplo</p> <p>Morpheus tem etapas simples para a\u00e7\u00f5es como leitura e escrita em um arquivo e tamb\u00e9m est\u00e1gios mais complexos, como o est\u00e1gio de infer\u00eancia Triton, que pode enviar muitas infer\u00eancias ass\u00edncronas solicita\u00e7\u00f5es usando mem\u00f3ria de dispositivo compartilhada.</p> <p>Embora os est\u00e1gios sejam muito flexiveis, todos eles precisam de tr\u00eas partes principais:</p>"},{"location":"Morpheus/2.arquitetura_morpheus/#identificacao","title":"Identifica\u00e7\u00e3o","text":"<p>O identificador do est\u00e1gio que \u00e9 uma String exclusiva usada para registrar e criar o est\u00e1gio a partir do CLI.</p>"},{"location":"Morpheus/2.arquitetura_morpheus/#tipo-de-inferencia","title":"Tipo de Infer\u00eancia","text":"<p>Para realizar o trabalho o Morpheus precisa saber quais os tipos de dados que ser\u00e1 utilizado em cada Est\u00e1gio. O Pipeline precisa garantir que os tipos de dados sejam compat\u00edveis em todas as conex\u00f5es de bordas entre os est\u00e1gios.</p> <p>A sa\u00edda de um est\u00e1gio depende da entrada do pr\u00f3ximo, um exemplo simples seria se a entrada do pr\u00f3ximo est\u00e1gio fosse uma String, o resultado do est\u00e1gio anterior precisaria ser em formato de String tamb\u00e9m. </p> <p>Realizado durante a fase de constru\u00e7\u00e3o do Pipeline.</p>"},{"location":"Morpheus/2.arquitetura_morpheus/#criacao-de-no","title":"Cria\u00e7\u00e3o de N\u00f3","text":"<p>A parte mais importante de um est\u00e1gio \u00e9 a cria\u00e7\u00e3o do n\u00f3. A fun\u00e7\u00e3o de cria\u00e7\u00e3o de n\u00f3 \u00e9 respons\u00e1vel por criar as inst\u00e2ncias dos n\u00f3s que comp\u00f5em um est\u00e1gio. Como um pipeline, os est\u00e1gios podem ser constru\u00eddos de um ou mais n\u00f3s menores conectado por bordas.</p>"},{"location":"Morpheus/2.arquitetura_morpheus/#camada-de-modulos","title":"Camada de M\u00f3dulos","text":"<p>Introduzido recentemente na vers\u00e3o 23.03, \u00e9 um novo m\u00e9todo para definir unidades de trabalho compactas que podem ser reutilizadas em v\u00e1rias pipelines diferentes como um novo ModuleStage ou carregado diretamente no contexto de um est\u00e1gio existente.</p>"},{"location":"Morpheus/2.arquitetura_morpheus/#resumo","title":"Resumo","text":"<p>Camada de Pipeline</p> <ul> <li>Composto por um ou mais est\u00e1gios conectados por arestas.</li> <li>Os dados se movem entre os est\u00e1gios usando canais em buffer, e o pipeline lidar\u00e1 automaticamente com a contrapress\u00e3o monitorando a quantidade de dados em cada buffer de borda.</li> </ul> <p>Camada de Est\u00e1gio</p> <ul> <li>Principais blocos de constru\u00e7\u00e3o em Morpheus.</li> <li>Respons\u00e1vel pela execu\u00e7\u00e3o de uma fun\u00e7\u00e3o espec\u00edfica em dados recebidos de est\u00e1gios anteriores no pipeline.</li> <li>Isolados um do outro e podem ser pensados como caixas pretas.</li> <li>Composto por um ou mais n\u00f3s, conectados por arestas.</li> <li>Todos os n\u00f3s s\u00e3o garantidos para operar na mesma m\u00e1quina, no mesmo espa\u00e7o de processo.</li> </ul>"},{"location":"Morpheus/3.cria%C3%A7%C3%A3o_de_est%C3%A1gios/","title":"3. Cria\u00e7\u00e3o e Configura\u00e7\u00e3o de Est\u00e1gios no Morpheus","text":"<p>Os est\u00e1gios do Morpheus s\u00e3o conectados iguais a um grafo, onde cada n\u00f3 \u00e9 um est\u00e1gio que recebe os dados e retornam outro, \u00e9 preciso deixar claro os tipos dos dados de entrada e de sa\u00edda para que o Morpheus possa conferir na hora da execu\u00e7\u00e3o da pipeline.</p> <p>Note</p> <p>\u00c9 poss\u00edvel criar uma fun\u00e7\u00e3o ou uma classe para o est\u00e1gio, permitindo mais flexibilidade na cria\u00e7\u00e3o do est\u00e1gio.</p>"},{"location":"Morpheus/3.cria%C3%A7%C3%A3o_de_est%C3%A1gios/#funcoes-como-estagio","title":"Fun\u00e7\u00f5es como Est\u00e1gio","text":"<p>Toda fun\u00e7\u00e3o precisa da anota\u00e7\u00e3o <code>@stage</code> que \u00e9 responsavel por deixar claro para o Morpheus que se trata de uma fun\u00e7\u00e3o que ser\u00e1 utilizada como um est\u00e1gio.</p> <pre><code>@stage\ndef pass_thru_stage(message: typing.Any) -&gt; typing.Any:\n    # Retorna mensagem para o proximo est\u00e1gio (aqui ficaria a l\u00f3gica do est\u00e1gio)\n    return message\n\n\n# --- Implementando no Pipeline ---\nconfig = Config()\npipeline = LinearPipeline(config)\n# ...\npipeline.add_stage(pass_thru_stage(config))\n</code></pre> <p>\u00c9 preciso tamb\u00e9m deixar claro o tipo da mensagem que ser\u00e1 recebida <code>message: typing.Any</code> e o tipo do retorno <code>-&gt; typing.Any</code> para que o Morpheus possa conferir ao criar o n\u00f3.</p>"},{"location":"Morpheus/3.cria%C3%A7%C3%A3o_de_est%C3%A1gios/#classes-como-estagio","title":"Classes como Est\u00e1gio","text":"<p>Ao optarmos por utilizar uma classe, precisamos especificar o tipo da classe herdando alguma pr\u00e9-definida pelo Morpheus, alguns exemplos:</p> Tipo Descri\u00e7\u00e3o SinglePortStage Est\u00e1gios que cont\u00e9m apenas uma entrada e sa\u00edda. SingleOutputSource Est\u00e1gios que atuam como fontes de dados, no sentido que n\u00e3o recebe uma entrada de um est\u00e1gio anterior, por exemplo: algum arquivo ou mensageria com Kafka. PassThruTypeMixin Define que o tipo da mensagem de entrada \u00e9 o mesmo do de sa\u00edda (muito comum no Morpheus). <p>Note</p> <p>Caso queira utilizar a classe especificada no CLI, precisamos utilizar um decorador na classe chamado de <code>@register_stage(\"pass-thru\")</code> fazendo com que seja poss\u00edvel a detec\u00e7\u00e3o na hora da cria\u00e7\u00e3o da pipeline. <pre><code>@register_stage(\"pass-thru\")\nclass PassThruStage(PassThruTypeMixin, SinglePortStage):\n</code></pre></p> <p>\u00c9 preciso criar 5 m\u00e9todos na subclasse para implementar a interface stage: <code>name</code> , <code>accepted_types</code> , <code>compute_schema</code> , <code>supports_cpp_node</code> e <code>_build_single</code> . Na pr\u00e1tica \u00e9 necess\u00e1rio definir mais um m\u00e9todo que executar\u00e1 o trabalho real do est\u00e1gio, por conven\u00e7\u00e3o se chama <code>on_data</code> .</p> <p>Note</p> <p>\u00c9 necess\u00e1rio colocar a anota\u00e7\u00e3o <code>@property</code> antes de inserir esses m\u00e9todos</p> nameaccepted_typescompute_schemasupports_cpp_node_build_singleon_data <p>Utilizada para retornar um nome mais amig\u00e1vel para o est\u00e1gio, usada apenas para fins de depura\u00e7\u00e3o. <pre><code>def name(self) -&gt; str:\n    return \"pass-thru\"\n</code></pre></p> <p>Retorna uma tupla de classes de mensagem que este est\u00e1gio \u00e9 capaz de aceitar como entrada. (Permite que o Morpheus valide se a sa\u00edda do pai desse est\u00e1gio \u00e9 o mesmo da entrada). <pre><code>def accepted_types(self) -&gt; tuple:\n    return (typing.Any,)\n</code></pre></p> <p>Retorna o tipo de sa\u00edda do est\u00e1gio (Como vamos herdar da classe <code>PassThruTypeMixin</code>, n\u00e3o precisamos utiliza-la): <pre><code>def compute_schema(self, schema: StageSchema):\n    schema.output_schema.set_type(schema.input_type)\n</code></pre></p> <p>Retorna se estamos utilizando arquivos CPP nesse est\u00e1gio. <pre><code>def supports_cpp_node(self) -&gt; bool:\n    return False\n</code></pre></p> <p>M\u00e9todo que ser\u00e1 usado no momento de constru\u00e7\u00e3o do est\u00e1gio, para construir o n\u00f3 e conecta-lo ao pipeline, ele recebe uma inst\u00e2ncia de um construtor do mrc(Morpheus Runtime Core) do tipo <code>mrc.Builder</code>, junto com um n\u00f3 de entrada do tipo <code>SegmentObject</code> e retorna um n\u00f3 rec\u00e9m constru\u00eddo. <pre><code>def _build_single(self, builder: mrc.Builder, input_node: mrc.SegmentObject) -&gt; mrc.SegmentObject:\n    node = builder.make_node(self.unique_name, ops.map(self.on_data))\n    builder.make_edge(input_node, node)\n\n    return node\n</code></pre></p> <p>Linha a linha:</p> <p><code>node = builder.make_node(self.unique_name, ops.map(self.on_data))</code></p> <p>Cria um n\u00f3 com o nome que demos para a classe junto a um ID \u00fanico para que n\u00e3o seja poss\u00edvel existir est\u00e1gios com mesmo nome;</p> <p><code>builder.make_edge(input_node, node)</code></p> <p>Define uma aresta conectando o novo n\u00f3 ao n\u00f3 pai.</p> <p>Aceita uma mensagem recebida e retorna uma mensagem (l\u00f3gica do est\u00e1gio) <pre><code>def on_data(self, message: typing.Any):\n    # Retorna mensagem para o proximo est\u00e1gio\n    return message\n</code></pre></p> <p>A Classe completa ficar\u00e1 assim:</p> <pre><code>import typing\n\nimport mrc\nfrom mrc.core import operators as ops\n\nfrom morpheus.cli.register_stage import register_stage\nfrom morpheus.pipeline.pass_thru_type_mixin import PassThruTypeMixin\nfrom morpheus.pipeline.single_port_stage import SinglePortStage\n\n\n@register_stage(\"pass-thru\")\nclass PassThruStage(PassThruTypeMixin, SinglePortStage):\n\n    @property\n    def name(self) -&gt; str:\n        return \"pass-thru\"\n\n    def accepted_types(self) -&gt; tuple:\n        return (typing.Any, )\n\n    def supports_cpp_node(self) -&gt; bool:\n        return False\n\n    def on_data(self, message: typing.Any):\n        # Retorna a mensagem para o pr\u00f3ximo estagio\n        return message\n\n    def _build_single(self, builder: mrc.Builder, input_node: mrc.SegmentObject) -&gt; mrc.SegmentObject:\n        node = builder.make_node(self.unique_name, ops.map(self.on_data))\n        builder.make_edge(input_node, node)\n\n        return node\n</code></pre>"},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/","title":"4. Tipos de Est\u00e1gios no Morpheus","text":"<p>Morpheus aceita v\u00e1rios tipos de est\u00e1gios diferentes, trazendo mais flexibilidade para cria\u00e7\u00e3o de pipelines. Abaixo est\u00e1 alguns dos est\u00e1gios mais usados.</p>"},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/#doca","title":"Doca","text":"Est\u00e1gio Descri\u00e7\u00e3o <code>DocaSourceStage</code> Est\u00e1gio de origem usado para receber dados de pacotes brutos utilizando a ferramenta DOCA da NVIDIA (Compat\u00edvel apenas com DPU's). <code>DocaConvertStage</code> Converte o formato recebido pelo <code>DocaSourceStage</code> em um formato de mensagem <code>MetaMessage</code>."},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/#geral","title":"Geral","text":"Est\u00e1gio Descri\u00e7\u00e3o <code>LinearModulesStage</code> Carrega um m\u00f3dulo existente e utiliza como um est\u00e1gio do Morpheus. <code>MultiPortModulesStage</code> Carrega um m\u00f3dulo existente, multi-porta e utiliza como um est\u00e1gio do Morpheus. <code>MonitorStage</code> Exibe a taxa de transfer\u00eancia do est\u00e1gio anterior no pipeline em paralelo. <code>TriggerStage</code> Armazena todas as entradas em buffer at\u00e9 que o est\u00e1gio de origem esteja completo."},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/#inferencia","title":"Infer\u00eancia","text":"Est\u00e1gio Descri\u00e7\u00e3o <code>AutoEncoderInferenceStage</code> Est\u00e1gio de infer\u00eancia PyTorch usado para o modo de pipeline Auto Encoder. <code>PyTorchInferenceStage</code> Est\u00e1gio de infer\u00eancia PyTorch usado para a maioria dos modos de pipelines, exceto Auto Encoder. <code>TritonInferenceStage</code> Est\u00e1gio de infer\u00eancia que utiliza o Triton Inference Server."},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/#entrada-fontes","title":"Entrada (Fontes)","text":"Est\u00e1gio Descri\u00e7\u00e3o <code>AppShieldSourceStage</code> Carrega mensagens do Appshield de um ou mais plugins em um dataframe. <code>AzureSourceStage</code> Carrega mensagens do Azure Active Directory. <code>CloudTrailSourceStage</code> Carrega mensagens de um diret\u00f3rio Cloudtrail. <code>ControlMessageFileSourceStage</code> Recebe mensagens de controle de diferentes fontes especificadas por uma lista de strings (fsspec). <code>ControlMessageKafkaSourceStage</code> Carrega mensagens de controle de um cluster Kafka. <code>DataBricksDeltaLakeSourceStage</code> Carrega mensagens de uma tabela DeltaLake. <code>DuoSourceStage</code> Carrega mensagens de autentica\u00e7\u00e3o Duo. <code>FileSourceStage</code> Carrega mensagens de um arquivo. <code>HttpClientSourceStage</code> Pesquisa um servidor HTTP remoto para dados recebidos. <code>HttpServerSourceStage</code> Inicia um servidor HTTP e ouve solicita\u00e7\u00f5es recebidas em um endpoint especificado. <code>InMemorySourceStage</code> Emite uma lista predefinida de dataframes. <code>KafkaSourceStage</code> Carrega mensagens de um cluster Kafka. <code>RSSSourceStage</code> Carrega itens de feed RSS em um pandas DataFrame."},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/#saida","title":"Sa\u00edda","text":"Est\u00e1gio Descri\u00e7\u00e3o <code>HttpClientSinkStage</code> Escreve todas as mensagens para um endpoint HTTP. <code>HttpServerSinkStage</code> Inicia um servidor HTTP e ouve solicita\u00e7\u00f5es recebidas em um endpoint especificado. <code>InMemorySinkStage</code> Coleta as mensagens recebidas em uma lista que pode ser acessada ap\u00f3s a conclus\u00e3o do pipeline. <code>DataBricksDeltaLakeSinkStage</code> Escreve mensagens para uma tabela DeltaLake. <code>WriteToElasticsearchStage</code> Escreve as mensagens como documentos para o Elasticsearch. <code>WriteToFileStage</code> Escreve todas as mensagens em um arquivo. <code>WriteToKafkaStage</code> Escreve todas as mensagens para um cluster Kafka. <code>WriteToVectorDBStage</code> Escreve todas as mensagens em um Banco de Dados Vetorial."},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/#pos-processamento","title":"P\u00f3s-processamento","text":"Est\u00e1gio Descri\u00e7\u00e3o <code>AddClassificationsStage</code> Adiciona classifica\u00e7\u00f5es detectadas a cada mensagem. <code>AddScoresStage</code> Adiciona pontua\u00e7\u00f5es de probabilidade a cada mensagem. <code>FilterDetectionsStage</code> Filtraa mensagem por um limite de classifica\u00e7\u00e3o. <code>GenerateVizFramesStage</code> Escreve a visualiza\u00e7\u00e3o DataFrames. <code>MLFlowDriftStage</code> Relata as estat\u00edsticas de drift do modelo para MLflow. <code>SerializeStage</code> Inclui e remove colunas de mensagens. <code>TimeSeriesStage</code> Executa a detec\u00e7\u00e3o da anomalia da s\u00e9rie temporal e adicione a previs\u00e3o."},{"location":"Morpheus/4.tipos_de_est%C3%A1gios/#pre-processamento","title":"Pr\u00e9-processamento","text":"Est\u00e1gio Descri\u00e7\u00e3o <code>DeserializeStage</code> Particiona as mensagens com base no par\u00e2metro pipeline_batch_size da configura\u00e7\u00e3o do pipeline. <code>DropNullStage</code> Remove entradas de dados nulas de um DataFrame. <code>PreprocessAEStage</code> Prepara DataFrames de entrada para infer\u00eancia em um Autoencoder. <code>PreprocessFILStage</code> Prepara DataFrames de entrada para infer\u00eancia em FIL. <code>PreprocessNLPStage</code> Prepara DataFrames de entrada para infer\u00eancia em NLP. <code>TrainAEStage</code> Treina um modelo de Autoencoder nos dados recebidos."},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/","title":"5.1 Pipelines com CLI","text":"<p>As cria\u00e7\u00f5es de pipelines do Morpheus podem ser feitas atr\u00e1ves do CLI, onde os est\u00e1gios s\u00e3o executados de forma linear, significando que a sa\u00edda de um est\u00e1gio \u00e9 a entrada do pr\u00f3ximo.</p> <p>Note</p> <p>Existem diferentes tipos de comandos possiveis no Morpheus, para saber mais sobre cada uma delas, verifique utilizando:</p> <pre><code>morpheus run --help\n</code></pre> <p>Ou na pr\u00f3pria documenta\u00e7\u00e3o do Morpheus.</p>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/#exemplo","title":"Exemplo","text":"<p>Para explicar o funcionamento a partir do CLI, ser\u00e1 utilizado um exemplo de execu\u00e7\u00e3o de uma Pipeline para detec\u00e7\u00e3o de minera\u00e7\u00e3o de criptomoedas na GPU.</p> <p>Warning</p> <p>Para a execu\u00e7\u00e3o desse exemplo, \u00e9 necess\u00e1rio que voc\u00ea tenha clonado o reposit\u00f3rio do Morpheus;</p> <pre><code>MORPHEUS_ROOT=$(pwd)/morpheus\ngit clone https://github.com/nv-morpheus/Morpheus.git $MORPHEUS_ROOT\ncd $MORPHEUS_ROOT\n</code></pre> <p>e que tenha executado o script para o download dos arquivos maiores.</p> <pre><code>scripts/fetch_data.py fetch examples models\n</code></pre> <p>ou se preferir, verifique a documenta\u00e7\u00e3o do Morpheus na sess\u00e3o Git LFS.</p>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/#executando-triton","title":"Executando Triton","text":"<p>Antes que voc\u00ea execute o Pipeline no Morpheus, \u00e9 necess\u00e1rio que voc\u00ea inicialize o modelo com o Triton Server.</p> <pre><code>docker run --rm -ti --gpus=all -p8000:8000 -p8001:8001 -p8002:8002\\\n    -v $PWD/models:/models nvcr.io/nvidia/tritonserver:23.06-py3 tritonserver\\\n        --model-repository=/models/triton-model-repo\\\n        --exit-on-error=false\\\n        --model-control-mode=explicit\\\n        --load-model abp-nvsmi-xgb\n</code></pre> <p>obs.: Esse comando considera que voc\u00ea esteja na pasta root do Morpheus.</p> <p>Ao subir o modelo, \u00e9 preciso que tenha exibido o seguinte resultado:</p> <pre><code>+-------------------+---------+--------+\n| Model             | Version | Status |\n+-------------------+---------+--------+\n| abp-nvsmi-xgb     | 1       | READY  |\n+-------------------+---------+--------+\n</code></pre>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/#executando-o-morpheus","title":"Executando o Morpheus","text":"<p>O c\u00f3digo a ser executado nesse exemplo ser\u00e1:</p> <pre><code>morpheus --log_level=DEBUG \\\n    run --num_threads=8 --pipeline_batch_size=1024 --model_max_batch_size=1024 \\\n    pipeline-fil --columns_file=data/columns_fil.txt \\\n    from-file --filename=examples/data/nvsmi.jsonlines \\\n    deserialize \\\n    preprocess \\\n    inf-triton --model_name=abp-nvsmi-xgb --server_url=localhost:8000 \\\n    monitor --description \"Inference Rate\" --smoothing=0.001 --unit inf \\\n    add-class \\\n    serialize --include 'mining' \\\n    to-file --filename=detections.jsonlines --overwrite\n</code></pre> <p>Para o entendimento, iremos analisar linha a linha do comando.</p> <pre><code># Define o nivel do log para o modo de Debug\n\nmorpheus --log_level=DEBUG \\\n</code></pre> <pre><code># Executa um pipeline com 8 threads e um tamanho de lote de modelo de 1024\n# (deve ser igual ou menor que a configura\u00e7\u00e3o do Triton)\n\nrun --num_threads=8 --pipeline_batch_size=1024 --model_max_batch_size=1024 \\\n</code></pre> <pre><code># Especifica um pipeline FIL com 256 de comprimento de sequ\u00eancia\n# (deve corresponder \u00e0 configura\u00e7\u00e3o do Triton)\n\npipeline-fil --columns_file=data/columns_fil.txt \\\n</code></pre> <pre><code># Faz a leitura de um arquivo na pasta especificada\n\nfrom-file --filename=examples/data/nvsmi.jsonlines \\\n</code></pre> <pre><code># Disserializa o arquivo para poder ser processado\n\ndeserialize \\\n</code></pre> <pre><code># Pr\u00e9-processamento que converte as entradas para um token BERT\n\npreprocess \\\n</code></pre> <pre><code># Envia mensagem para o Triton fazer a inferencia\n# (\u00e9 necess\u00e1rio especificar o modelo)\n\ninf-triton --model_name=abp-nvsmi-xgb --server_url=localhost:8000 \\\n</code></pre> <pre><code># Monitora o est\u00e1gio anterior e exibe no console as informa\u00e7\u00f5es de performance\n\nmonitor --description \"Inference Rate\" --smoothing=0.001 --unit inf \\\n</code></pre> <pre><code># Adiciona o resultado de infer\u00eancia na mensagem\n\nadd-class \\\n</code></pre> <pre><code># Converte a mensagem de Objeto para String novamente,\n# contendo somente as informa\u00e7\u00f5es resultantes da infer\u00eancia\n\nserialize --include 'mining' \\\n</code></pre> <pre><code># Faz a escrita do resultado em um arquivo .jsonline\n\nto-file --filename=detections.jsonlines --overwrite\n</code></pre> <p>A ordem de execu\u00e7\u00e3o do Pipeline foi linear, onde a sa\u00edda do n\u00f3 anterior vai para a entrada do pr\u00f3ximo n\u00f3.</p>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/#resultado","title":"Resultado","text":"<p>Ao concluir a execu\u00e7\u00e3o do Pipeline, teremos os seguintes resultados.</p>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/#console","title":"Console","text":"<pre><code>...\n====Registering Pipeline====\n====Registering Pipeline Complete!====\n====Starting Pipeline====\n====Pipeline Started====\n====Building Pipeline====\nAdded source: &lt;from-file-0; FileSourceStage(filename=examples/data/nvsmi.jsonlines, iterative=False, file_type=FileTypes.Auto, repeat=1, filter_null=True)&gt;\n  \u2514\u2500&gt; morpheus.MessageMeta\nAdded stage: &lt;deserialize-1; DeserializeStage()&gt;\n  \u2514\u2500 morpheus.MessageMeta -&gt; morpheus.MultiMessage\nAdded stage: &lt;preprocess-fil-2; PreprocessFILStage()&gt;\n  \u2514\u2500 morpheus.MultiMessage -&gt; morpheus.MultiInferenceFILMessage\nAdded stage: &lt;inference-3; TritonInferenceStage(model_name=abp-nvsmi-xgb, server_url=localhost:8000, force_convert_inputs=False, use_shared_memory=False)&gt;\n  \u2514\u2500 morpheus.MultiInferenceFILMessage -&gt; morpheus.MultiResponseMessage\nAdded stage: &lt;monitor-4; MonitorStage(description=Inference Rate, smoothing=0.001, unit=inf, delayed_start=False, determine_count_fn=None)&gt;\n  \u2514\u2500 morpheus.MultiResponseMessage -&gt; morpheus.MultiResponseMessage\nAdded stage: &lt;add-class-5; AddClassificationsStage(threshold=0.5, labels=[], prefix=)&gt;\n  \u2514\u2500 morpheus.MultiResponseMessage -&gt; morpheus.MultiResponseMessage\nAdded stage: &lt;serialize-6; SerializeStage(include=['mining'], exclude=['^ID$', '^_ts_'], fixed_columns=True)&gt;\n  \u2514\u2500 morpheus.MultiResponseMessage -&gt; morpheus.MessageMeta\nAdded stage: &lt;to-file-7; WriteToFileStage(filename=detections.jsonlines, overwrite=True, file_type=FileTypes.Auto)&gt;\n  \u2514\u2500 morpheus.MessageMeta -&gt; morpheus.MessageMeta\n====Building Pipeline Complete!====\nStarting! Time: 1656353254.9919598\nInference Rate[Complete]: 1242inf [00:00, 1863.04inf/s]\n====Pipeline Complete====\n</code></pre> <p>Note</p> <p>Como utilizamos a configura\u00e7\u00e3o de Debug no Log, tivemos informa\u00e7\u00f5es de tudo que est\u00e1va acontecendo na cria\u00e7\u00e3o dos est\u00e1gios.</p>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/#arquivo","title":"Arquivo","text":"<pre><code>...\n{\"mining\": 0}\n{\"mining\": 0}\n{\"mining\": 0}\n{\"mining\": 0}\n{\"mining\": 1}\n{\"mining\": 1}\n{\"mining\": 1}\n{\"mining\": 1}\n{\"mining\": 1}\n{\"mining\": 1}\n{\"mining\": 1}\n{\"mining\": 1}\n...\n</code></pre> <p>Note</p> <p>Foi configurado no est\u00e1gio para ser gerado apenas o resultado da classifica\u00e7\u00e3o da infer\u00eancia.</p>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.1.pipelines_com_cli/#executando-estagios-em-python-com-cli","title":"Executando Est\u00e1gios em Python com CLI","text":"<p>Como alternativa ao Pipeline com Python, poder\u00edamos testar o est\u00e1gio baseado em classe em um pipeline constru\u00eddo usando a ferramenta de linha de comando Morpheus. Precisaremos passar o caminho para nosso est\u00e1gio por meio do\u00a0argumento <code>--plugin</code> para que ele fique vis\u00edvel para a ferramenta de linha de comando.</p> <p>Warning</p> <p>At\u00e9 o momento s\u00f3 \u00e9 poss\u00edvel registar o est\u00e1gio feito em classes.</p> <pre><code>morpheus --log_level=debug --plugin examples/developer_guide/1_simple_python_stage/pass_thru.py \\\n  run pipeline-other \\\n  from-file --filename=examples/data/email_with_addresses.jsonlines \\\n  pass-thru \\\n  monitor\n</code></pre>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.2.pipelines_com_python/","title":"5.2 Pipelines com Python","text":"<p>Antes de construir o pipeline \u00e9 preciso configurar o ambiente, come\u00e7ando com o log:</p> <pre><code>configure_logging(log_level=logging.DEBUG)\n</code></pre> <p>Os manipuladores de registro n\u00e3o s\u00e3o bloqueantes, pois utilizam uma fila para enviar as mensagens de registro em um thread separado.</p> <p>Note</p> <p>Podemos utilizar a fun\u00e7\u00e3o\u00a0<code>configure_logging</code> para adicionar um ou mais manipuladores de registro \u00e0 configura\u00e7\u00e3o padr\u00e3o, um exemplo disso seria:</p> <pre><code>loki_handler = logging_loki.LokiHandler(\n    url=f\"{loki_url}/loki/api/v1/push\",\n    tags={\"app\": \"morpheus\"},\n    version=\"1\",\n)\n\nconfigure_logging(loki_handler, log_level=log_level)\n</code></pre> <p>Onde \u00e9 adicionado um manipulador de log chamado Grafana Loki que cria logs \u00fanicos para depura\u00e7\u00e3o posteriormente.</p> <p>Ap\u00f3s configurarmos o Log, precisamos criar uma inst\u00e2ncia de configura\u00e7\u00e3o (sempre ser\u00e1 necess\u00e1rio):</p> <pre><code>config = Config()\n</code></pre> <p>Para o exemplo ser\u00e1 utilizado a classe <code>FileSourceStage</code> , para ler um arquivo grande no qual cada linha \u00e9 um objeto JSON. O est\u00e1gio pegar\u00e1 essas linhas e as empacotar\u00e1 como objetos de mensagem Morpheus para nosso est\u00e1gio de passagem consumir.</p> <pre><code>pipeline.set_source(FileSourceStage(config, filename=input_file, iterative=False))\n</code></pre> <p>Em Seguida \u00e9 adicionado os est\u00e1gios ao pipeline, junto com a inst\u00e2ncia <code>MonitorStage</code> , para monitorar a taxa de transfer\u00eancia dos est\u00e1gios:</p> <pre><code># Adiciona a fun\u00e7\u00e3o de est\u00e1gio com o decorador @stage\npipeline.add_stage(pass_thru_stage(config))\n\n# Adiciona o monitoramento de performance do est\u00e1gio anterior\npipeline.add_stage(MonitorStage(config))\n\n# Adiciona a classe criada como est\u00e1gio\npipeline.add_stage(PassThruStage(config))\n\n# Adiciona o monitoramento de performance do est\u00e1gio anterior\npipeline.add_stage(MonitorStage(config))\n</code></pre>"},{"location":"Morpheus/5.%20Gerenciamento%20de%20Pipelines%20no%20Morpheus/5.2.pipelines_com_python/#pipeline-completo","title":"Pipeline Completo","text":"<pre><code>import logging\nimport os\n\nfrom pass_thru import PassThruStage\nfrom pass_thru_deco import pass_thru_stage\n\nfrom morpheus.config import Config\nfrom morpheus.pipeline import LinearPipeline\nfrom morpheus.stages.general.monitor_stage import MonitorStage\nfrom morpheus.stages.input.file_source_stage import FileSourceStage\nfrom morpheus.utils.logger import configure_logging\n\ndef run_pipeline():\n    # Configura o Log do Morpheus\n    configure_logging(log_level=logging.DEBUG)\n\n    root_dir = os.environ['MORPHEUS_ROOT']\n    input_file = os.path.join(root_dir, 'examples/data/email_with_addresses.jsonlines')\n\n    config = Config()\n\n    # Cria um Objeto para pipeline linear (a saida de um est\u00e1gio \u00e9 a entrada da outra na ordem que foi criada)\n    pipeline = LinearPipeline(config)\n\n    # Faz a leitura do arquivo JSON\n    pipeline.set_source(FileSourceStage(config, filename=input_file, iterative=False))\n\n    # Adiciona a fun\u00e7\u00e3o de est\u00e1gio com o decorador @stage\n    pipeline.add_stage(pass_thru_stage(config))\n\n    # Adiciona o monitoramento de performance do est\u00e1gio anterior\n    pipeline.add_stage(MonitorStage(config))\n\n    # Adiciona a classe criada como est\u00e1gio\n    pipeline.add_stage(PassThruStage(config))\n\n    # Adiciona o monitoramento de performance do est\u00e1gio anterior\n    pipeline.add_stage(MonitorStage(config))\n\n    pipeline.run()\n\nif __name__ == \"__main__\":\n    run_pipeline()\n</code></pre>"},{"location":"SIEM/0.introdu%C3%A7%C3%A3o/","title":"0. Introdu\u00e7\u00e3o ao SIEM","text":""},{"location":"SIEM/0.introdu%C3%A7%C3%A3o/#conceito-e-objetivo-de-um-siem","title":"Conceito e Objetivo de um SIEM","text":"<p>Um SIEM (Security Information and Event Management) \u00e9 uma solu\u00e7\u00e3o que integra duas tecnologias principais, o SEM (Security Event Management) e o SIM (Security Information Management), para monitorar, analisar e responder a eventos de seguran\u00e7a em uma rede.</p> <p>Note</p> <p> SEM (Security Event Management) Processo de monitoramento e an\u00e1lise de eventos de seguran\u00e7a para identificar padr\u00f5es suspeitos e gerar alertas para incidentes de seguran\u00e7a.</p> <p> SIM (Security Information Management) Processo de coleta, armazenamento e an\u00e1lise de dados hist\u00f3ricos relacionados \u00e0 seguran\u00e7a provenientes de v\u00e1rias fontes.  </p> <p>O SIEM \u00e9 respons\u00e1vel por v\u00e1rias fun\u00e7\u00f5es, como coleta de logs, armazenamento, correla\u00e7\u00e3o, cria\u00e7\u00e3o de relat\u00f3rios. Com o SIEM, \u00e9 poss\u00edvel detectar sinais de comportamentos suspeitos ou padr\u00f5es que precedem um ataque, tornando-se, assim, uma das principais ferramentas para a seguran\u00e7a da informa\u00e7\u00e3o.</p>"},{"location":"SIEM/0.introdu%C3%A7%C3%A3o/#funcionamento-e-estrutura-de-um-siem","title":"Funcionamento e Estrutura de um SIEM","text":"<p>O SIEM coleta dados de v\u00e1rias fontes, incluindo computadores, dispositivos de rede, servidores, entre outros. Esses dados s\u00e3o ent\u00e3o normalizados para facilitar a an\u00e1lise pela ferramenta de correla\u00e7\u00e3o de eventos. Quando uma amea\u00e7a \u00e9 identificada, uma notifica\u00e7\u00e3o \u00e9 enviada \u00e0 equipe de seguran\u00e7a para que a situa\u00e7\u00e3o seja investigada e/ou bloqueada automaticamente por outras ferramentas.</p> <p>Uma solu\u00e7\u00e3o SIEM coleta logs por v\u00e1rios protocolos e tipos de conectores (por exemplo, Syslog, SNMP, API, etc.), ao receb\u00ea-los, \u00e9 preciso diversas funcionalidades al\u00e9m da coleta, tais como:</p> <ul> <li>Administra\u00e7\u00e3o de logs</li> <li>Capacidade de examinar logs e outros tipos de dados</li> <li>Tratamento de incidentes</li> <li>Resumos visuais (relat\u00f3rios, gr\u00e1ficos, etc.)</li> <li>Documenta\u00e7\u00e3o</li> </ul> <p>Warning</p> <p>Um SIEM n\u00e3o substitui outras ferramentas de monitoramento; ele opera em conjunto com elas, processando dados de logs para identificar eventos que podem levar \u00e0 explora\u00e7\u00e3o do sistema.</p>"},{"location":"SIEM/0.introdu%C3%A7%C3%A3o/#principais-requisitos-para-implementacao-de-um-siem","title":"Principais Requisitos para Implementa\u00e7\u00e3o de um SIEM","text":"<ul> <li> <p>Agrega\u00e7\u00e3o e normaliza\u00e7\u00e3o de logs Uma das principais fun\u00e7\u00f5es de um SIEM \u00e9 agregar logs de v\u00e1rias fontes e normaliza-los para padronizar os dados, facilitando o processo de correla\u00e7\u00e3o posteriormente e permitindo uma analise mais precisa.</p> </li> <li> <p>Alertas de amea\u00e7as Ao identificar uma poss\u00edvel amea\u00e7a, o SIEM gera um alerta que pode ser configurado pela equipe de SOC para acionar notifica\u00e7\u00f5es, como envio de e-mails, atualiza\u00e7\u00e3o de dashboards, entre outros.</p> </li> <li> <p>Contextualiza\u00e7\u00e3o e resposta Apenas gerar alertas n\u00e3o \u00e9 suficiente, pois podem ocorrer falsos positivos se o sistema n\u00e3o for configurado corretamente, sobrecarregando a equipe de seguran\u00e7a. A contextualiza\u00e7\u00e3o permite que a equipe filtre amea\u00e7as genu\u00ednas com mais precis\u00e3o. A contextualiza\u00e7\u00e3o geralmente depende de regras e do uso de an\u00e1lises adicionais.</p> </li> <li> <p>Conformidade O SIEM ajuda as organiza\u00e7\u00f5es a atender requisitos regulat\u00f3rios, como PCI DSS, HIPAA e GDPR, que exigem medidas robustas de seguran\u00e7a. Solu\u00e7\u00f5es SIEM tamb\u00e9m oferecem recursos para automa\u00e7\u00e3o de relat\u00f3rios, um recurso essencial para conformidade.</p> </li> </ul>"},{"location":"SIEM/0.introdu%C3%A7%C3%A3o/#processamento-e-fluxo-de-dados-em-um-siem","title":"Processamento e Fluxo de Dados em um SIEM","text":"<ol> <li>A solu\u00e7\u00e3o SIEM agrega logs de v\u00e1rias fontes.</li> <li>Os dados coletados s\u00e3o processados e normalizados para que possam ser compreendidos pela ferramenta SIEM. Os dados brutos precisam ser gravados ou lidos em um formato que a ferramenta entenda e, ent\u00e3o, convertidos para um formato comum a partir de diversos tipos de conjuntos de dados (normaliza\u00e7\u00e3o e agrega\u00e7\u00e3o de dados).</li> <li>A parte crucial de um SIEM: a equipe de SOC utiliza os dados normalizados para criar regras de detec\u00e7\u00e3o, pain\u00e9is, visualiza\u00e7\u00f5es, alertas e incidentes. Isso permite que a equipe de SOC identifique rapidamente poss\u00edveis riscos, minimizando os danos.</li> </ol>"},{"location":"SIEM/0.introdu%C3%A7%C3%A3o/#beneficios-de-utilizar-um-siem","title":"Benef\u00edcios de Utilizar um SIEM","text":"<p>Sem um SIEM, a equipe de seguran\u00e7a de TI n\u00e3o teria uma vis\u00e3o centralizada de todos os dados e eventos em tempo real vindos de diferentes fontes, o que aumentaria o tempo de investiga\u00e7\u00e3o. Por exemplo, se um firewall registra cinco tentativas de login incorretas, resultando no bloqueio da conta de administrador, \u00e9 essencial ter um sistema centralizado de registros que correlacione esses eventos para monitorar a situa\u00e7\u00e3o.</p>"},{"location":"SIEM/0.introdu%C3%A7%C3%A3o/#desafios-e-limitacoes-dos-siems-atuais","title":"Desafios e Limita\u00e7\u00f5es dos SIEMs Atuais","text":"<p>Existem limita\u00e7\u00f5es na abordagem baseada em regras usada nos m\u00f3dulos de correla\u00e7\u00e3o, como a necessidade constante de atualizar as regras e a dificuldade em detectar amea\u00e7as avan\u00e7adas, como ataques de dia zero e amea\u00e7as persistentes (APT). Outra limita\u00e7\u00e3o comum \u00e9 o volume de falsos positivos, que exige a interven\u00e7\u00e3o humana para priorizar eventos.</p>"},{"location":"Triton%20Inference%20Server/0.introdu%C3%A7%C3%A3o/","title":"0. Introdu\u00e7\u00e3o ao Triton","text":"<p>Triton Inference Server como o nome ja diz, \u00e9 responsavel pela execu\u00e7\u00e3o de infer\u00eancias em modelos treinados de machine learning ou deep learning de qualquer framework em qualquer processador (GPU, CPU ou outro) com o Servidor de Infer\u00eancia.</p> <p>Fornece uma solu\u00e7\u00e3o de infer\u00eancia de nuvem e borda otimizada por CPUs e GPUs. O Triton suporta um protocolo HTTP/REST e GRPC que permite que clientes remotos solicitem infer\u00eancia para qualquer modelo gerenciado pelo servidor.</p>"},{"location":"Triton%20Inference%20Server/0.introdu%C3%A7%C3%A3o/#principais-recursos","title":"Principais recursos","text":"<ul> <li>O Triton oferece baixa lat\u00eancia e alta taxa de transf\u00earencia para infer\u00eancia de grandes modelos.</li> <li>Permite executar cargas de trabalho com IA com v\u00e1rios modelos, pipelines e etapas de pr\u00e9 e p\u00f3s-processamento.</li> <li>O Analisador de Modelos reduz o tempo necess\u00e1rio para encontrar a configura\u00e7\u00e3o ideal de implanta\u00e7\u00e3o do modelo, como tamanho do lote, precis\u00e3o e inst\u00e2ncias de execu\u00e7\u00e3o simult\u00e2nea.</li> </ul>"},{"location":"Triton%20Inference%20Server/0.introdu%C3%A7%C3%A3o/#frameworks-suportados","title":"Frameworks suportados","text":"<p>\u00c9 suportado todos os principais modelos de IA em qualquer framework importante, incluindo:</p> <ul> <li>TensorRT</li> <li>ONNX Runtime</li> <li>TensorFlow</li> <li>PyTorch</li> <li>OpenVINO</li> <li>Python</li> <li>DALI</li> <li>FIL</li> <li>TensorRT-LLM</li> <li>vLLM</li> <li>XGBoost</li> <li>LightGBM</li> <li>Scikit-Learn</li> <li>cuML</li> </ul>"},{"location":"Triton%20Inference%20Server/0.introdu%C3%A7%C3%A3o/#hardware-suportado","title":"Hardware suportado","text":"<p>O Servidor de Infer\u00eancia Triton oferece suporte a todas as GPUs NVIDIA, CPUs x86, Arm e AWS Inferentia.</p>"},{"location":"Triton%20Inference%20Server/1.container_triton/","title":"1. Configura\u00e7\u00e3o do Triton com Docker","text":"<p>Muitos casos de testes onde \u00e9 necess\u00e1rio a analise dos dados a partir de uma IA \u00e9 preciso que tenha em execu\u00e7\u00e3o o Triton Inference Server, \u00e9 ele quem cuida da classifica\u00e7\u00e3o dos dados a partir do seu modelo pr\u00e9-treinado.</p> <p>No momento que estou escrevendo esse documento, o Triton Inference Server se encontra na vers\u00e3o 24.09.</p>"},{"location":"Triton%20Inference%20Server/1.container_triton/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Docker</li> <li>The NVIDIA Container Toolkit</li> </ul>"},{"location":"Triton%20Inference%20Server/1.container_triton/#download-da-imagem","title":"Download da Imagem","text":"<p>Com o Docker ja instalado na sua maquina, precisamos baixar a imagem na nuvem da NVIDIA (NGC).</p> <pre><code>docker pull nvcr.io/nvidia/tritonserver:24.09-trtllm-python-py3\n</code></pre> <p>Para verificar se o comando funcionou corretamente, execute o comando abaixo para listar todas as imagens instaladas no Docker:</p> <pre><code>docker ps\n</code></pre> Failure <p>Caso a imagem n\u00e3o se encontre na lista, verifique se inseriu a tag corretamente e tente novamente.</p>"},{"location":"Triton%20Inference%20Server/1.container_triton/#executando-o-triton-server","title":"Executando o Triton Server","text":"<p>A execu\u00e7\u00e3o do Triton Server depende do tipo do modelo que ser\u00e1 executado, oque varia de projeto para projeto.</p> <p>Exemplo de execu\u00e7\u00e3o:</p> <pre><code>docker run --rm -ti --gpus=all -p8000:8000 -p8001:8001 -p8002:8002\\\n    -v $PWD/models:/models\\\n    nvcr.io/nvidia/tritonserver:23.06-py3 tritonserver\\\n    --model-repository=/models/triton-model-repo\\\n    --exit-on-error=false\\\n    --log-info=true\\\n    --strict-readiness=false\\\n    --disable-auto-complete-config\n</code></pre> <p>Esse comando faz com que seja executado um cantainer docker do Triton que execute todos os modelos na pasta de reposit\u00f3rio especificada.</p> <p>Note</p> <p>Como n\u00e3o foi especificado nenhum modelo, o Triton Server ir\u00e1 executar todos os modelos que encontrar na pasta de reposit\u00f3rio.</p> <p>Para especificar o modelo utilize o comando: <pre><code>--load-model {{NOME-DO-MODELO}}\n</code></pre></p> <p>Depois que o Triton carregar o modelo, ser\u00e1 exibido algo parecido com:</p> <pre><code>+-------------------+---------+--------+\n| Model             | Version | Status |\n+-------------------+---------+--------+\n| {NOME-DO-MODELO}  | 1       | READY  |\n+-------------------+---------+--------+\n</code></pre> Failure <p>Se isso n\u00e3o estiver presente na sa\u00edda, verifique o log do Triton para quaisquer mensagens de erro relacionadas ao carregamento do modelo.</p>"}]}